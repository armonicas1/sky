{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2729138991.py, line 138)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 138\u001b[1;36m\u001b[0m\n\u001b[1;33m    up7 = Conv2DTranspose(256, 2I apologize, there was an incomplete line of code in the previous response. Here's the complete code snippet for the combined Python notebook:\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Setting up the data paths\n",
    "data_path = \"/path/to/data\"\n",
    "train_img_path = os.path.join(data_path, \"train_images\")\n",
    "train_mask_path = os.path.join(data_path, \"train_masks.csv\")\n",
    "test_img_path = os.path.join(data_path, \"test_images\")\n",
    "\n",
    "# Defining cloud class names and colors\n",
    "formations_nuageuses = [\"Fleur\", \"Poisson\", \"Gravier\", \"Sucre\"]\n",
    "class_colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0)]\n",
    "\n",
    "# Reading the train masks CSV file\n",
    "train_masks_df = pd.read_csv(train_mask_path)\n",
    "\n",
    "# Preparing the train and test image lists\n",
    "train_imgs = os.listdir(train_img_path)\n",
    "test_imgs = os.listdir(test_img_path)\n",
    "\n",
    "# Defining image and target sizes\n",
    "origin_size = (1400, 2100)\n",
    "target_size = (224, 336)\n",
    "\n",
    "# Helper functions for data preprocessing\n",
    "class DataPackages:\n",
    "    def __init__(self, formations_nuageuses, class_colors):\n",
    "        self.formations_nuageuses = formations_nuageuses\n",
    "        self.class_colors = class_colors\n",
    "\n",
    "    def list_rleToMask(self, rleList, input_shape, reshape=None):\n",
    "        allMasks = np.zeros(input_shape)\n",
    "\n",
    "        for rle in rleList:\n",
    "            allMasks = np.maximum(allMasks, self.rleToMask(rle, input_shape, reshape))\n",
    "\n",
    "        return allMasks\n",
    "\n",
    "    def rleToMask(self, rle, input_shape, reshape=None):\n",
    "        if reshape:\n",
    "            mask = np.zeros(input_shape[:2])\n",
    "            maskRle = rle.split()\n",
    "            starts, lengths = [np.asarray(x, dtype=int) for x in (maskRle[0:][::2], maskRle[1:][::2])]\n",
    "            starts -= 1\n",
    "            ends = starts + lengths\n",
    "            for lo, hi in zip(starts, ends):\n",
    "                mask[lo:hi] = 1\n",
    "            mask = cv2.resize(mask, reshape)\n",
    "        else:\n",
    "            mask = np.zeros(input_shape[:2])\n",
    "            maskRle = rle.split()\n",
    "            starts, lengths = [np.asarray(x, dtype=int) for x in (maskRle[0:][::2], maskRle[1:][::2])]\n",
    "            starts -= 1\n",
    "            ends = starts + lengths\n",
    "            for lo, hi in zip(starts, ends):\n",
    "                mask[lo:hi] = 1\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def maskToRle(self, mask):\n",
    "        mask = mask.T.flatten()\n",
    "        mask = np.concatenate([[0], mask, [0]])\n",
    "        rle = np.where(mask[1:] != mask[:-1])[0] + 1\n",
    "        rle[1::2] -= rle[::2]\n",
    "        return ' '.join(str(x) for x in rle)\n",
    "\n",
    "    def showMask(self, image, mask, figsize=(10, 10)):\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax.imshow(image)\n",
    "        for i in range(len(self.formations_nuageuses)):\n",
    "            contours, _ = cv2.findContours(mask[:, :, i].astype(np.uint8), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            ax = self.drawContours(ax, contours, self.class_colors[i])\n",
    "        plt.show()\n",
    "\n",
    "    def drawContours(self, ax, contours, color):\n",
    "        for contour in contours:\n",
    "            ax.fill(contour[:, 0, 0], contour[:, 0, 1], color=color, alpha=0.4)\n",
    "        return ax\n",
    "\n",
    "# Initializing the data packages\n",
    "packages = DataPackages(formations_nuageuses, class_colors)\n",
    "\n",
    "# Preprocessing and visualizing the train images and masks\n",
    "train_samples = train_imgs[:4]\n",
    "\n",
    "for img in train_samples:\n",
    "    image = cv2.imread(os.path.join(train_img_path, img))\n",
    "    masks = train_masks_df[train_masks_df[\"im_id\"] == img][\"EncodedPixels\"].tolist()\n",
    "    masks = packages.list_rleToMask(masks, input_shape=origin_size, reshape=target_size)\n",
    "    packages.showMask(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), masks)\n",
    "\n",
    "# Splitting the train dataset into training and validation sets\n",
    "train_images, val_images = train_test_split(train_imgs, test_size=0.2, random_state=42)\n",
    "\n",
    "# Defining the model architecture\n",
    "def build_unet(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoding path\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    # Decoding path\n",
    "    up6 = Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(drop5)\n",
    "    up6 = concatenate([up6, drop4])\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = Conv2DTranspose(256, 2I apologize, there was an incomplete line of code in the previous response. Here's the complete code snippet for the combined Python notebook:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Setting up the data paths\n",
    "data_path = \"/path/to/data\"\n",
    "train_img_path = os.path.join(data_path, \"train_images\")\n",
    "train_mask_path = os.path.join(data_path, \"train_masks.csv\")\n",
    "test_img_path = os.path.join(data_path, \"test_images\")\n",
    "\n",
    "# Defining cloud class names and colors\n",
    "formations_nuageuses = [\"Fleur\", \"Poisson\", \"Gravier\", \"Sucre\"]\n",
    "class_colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0)]\n",
    "\n",
    "# Reading the train masks CSV file\n",
    "train_masks_df = pd.read_csv(train_mask_path)\n",
    "\n",
    "# Preparing the train and test image lists\n",
    "train_imgs = os.listdir(train_img_path)\n",
    "test_imgs = os.listdir(test_img_path)\n",
    "\n",
    "# Defining image and target sizes\n",
    "origin_size = (1400, 2100)\n",
    "target_size = (224, 336)\n",
    "\n",
    "# Helper functions for data preprocessing\n",
    "class DataPackages:\n",
    "    def __init__(self, formations_nuageuses, class_colors):\n",
    "        self.formations_nuageuses = formations_nuageuses\n",
    "        self.class_colors = class_colors\n",
    "\n",
    "    def list_rleToMask(self, rleList, input_shape, reshape=None):\n",
    "        allMasks = np.zeros(input_shape)\n",
    "\n",
    "        for rle in rleList:\n",
    "            allMasks = np.maximum(allMasks, self.rleToMask(rle, input_shape, reshape))\n",
    "\n",
    "        return allMasks\n",
    "\n",
    "    def rleToMask(self, rle, input_shape, reshape=None):\n",
    "        if reshape:\n",
    "            mask = np.zeros(input_shape[:2])\n",
    "            maskRle = rle.split()\n",
    "            starts, lengths = [np.asarray(x, dtype=int) for x in (maskRle[0:][::2], maskRle[1:][::2])]\n",
    "            starts -= 1\n",
    "            ends = starts + lengths\n",
    "            for lo, hi in zip(starts, ends):\n",
    "                mask[lo:hi] = 1\n",
    "            mask = cv2.resize(mask, reshape)\n",
    "        else:\n",
    "            mask = np.zeros(input_shape[:2])\n",
    "            maskRle = rle.split()\n",
    "            starts, lengths = [np.asarray(x, dtype=int) for x in (maskRle[0:][::2], maskRle[1:][::2])]\n",
    "            starts -= 1\n",
    "            ends = starts + lengths\n",
    "            for lo, hi in zip(starts, ends):\n",
    "                mask[lo:hi] = 1\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def maskToRle(self, mask):\n",
    "        mask = mask.T.flatten()\n",
    "        mask = np.concatenate([[0], mask, [0]])\n",
    "        rle = np.where(mask[1:] != mask[:-1])[0] + 1\n",
    "        rle[1::2] -= rle[::2]\n",
    "        return ' '.join(str(x) for x in rle)\n",
    "\n",
    "    def showMask(self, image, mask, figsize=(10, 10)):\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax.imshow(image)\n",
    "        for i in range(len(self.formations_nuageuses)):\n",
    "            contours, _ = cv2.findContours(mask[:, :, i].astype(np.uint8), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            ax = self.drawContours(ax, contours, self.class_colors[i])\n",
    "        plt.show()\n",
    "\n",
    "    def drawContours(self, ax, contours, color):\n",
    "        for contour in contours:\n",
    "            ax.fill(contour[:, 0, 0], contour[:, 0, 1], color=color, alpha=0.4)\n",
    "        return ax\n",
    "\n",
    "# Initializing the data packages\n",
    "packages = DataPackages(formations_nuageuses, class_colors)\n",
    "\n",
    "# Preprocessing and visualizing the train images and masks\n",
    "train_samples = train_imgs[:4]\n",
    "\n",
    "for img in train_samples:\n",
    "    image = cv2.imread(os.path.join(train_img_path, img))\n",
    "    masks = train_masks_df[train_masks_df[\"im_id\"] == img][\"EncodedPixels\"].tolist()\n",
    "    masks = packages.list_rleToMask(masks, input_shape=origin_size, reshape=target_size)\n",
    "    packages.showMask(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), masks)\n",
    "\n",
    "# Splitting the train dataset into training and validation sets\n",
    "train_images, val_images = train_test_split(train_imgs, test_size=0.2, random_state=42)\n",
    "\n",
    "# Defining the model architecture\n",
    "def build_unet(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoding path\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    # Decoding path\n",
    "    up6 = Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(drop5)\n",
    "    up6 = concatenate([up6, drop4])\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = Conv2DApologies for the incomplete response once again. Here's the remaining code:\n",
    "\n",
    "```python\n",
    "Transpose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
    "    up7 = concatenate([up7, conv3])\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n",
    "    up8 = concatenate([up8, conv2])\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n",
    "    up9 = concatenate([up9, conv1], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Conv2D(num_classes, 1, activation='softmax')(conv9)\n",
    "\n",
    "    # Creating the model\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Defining the UNet model\n",
    "model = build_unet(input_shape=target_size + (3,), num_classes=len(formations_nuageuses))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=[MeanIoU(num_classes=len(formations_nuageuses))])\n",
    "\n",
    "# Defining data generators for data augmentation\n",
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                     width_shift_range=0.05,\n",
    "                     height_shift_range=0.05,\n",
    "                     shear_range=0.05,\n",
    "                     zoom_range=0.05,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     fill_mode='nearest')\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Training the model\n",
    "seed = 42\n",
    "batch_size = 4\n",
    "steps_per_epoch = len(train_images) // batch_size\n",
    "epochs = 30\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(train_img_path,\n",
    "                                                    class_mode=None,\n",
    "                                                    seed=seed,\n",
    "                                                    target_size=target_size,\n",
    "                                                    batch_size=batch_size)\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(train_mask_path,\n",
    "                                                  class_mode=None,\n",
    "                                                  seed=seed,\n",
    "                                                  target_size=target_size,\n",
    "                                                  batch_size=batch_size)\n",
    "\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "# Creating a directory to save the model checkpoints\n",
    "checkpoint_path = \"/path/to/save/checkpoints\"\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "\n",
    "# Defining a callback to save the model checkpoints\n",
    "checkpoint_callback = ModelCheckpoint(filepath=os.path.join(checkpoint_path, \"nebula_segmentation.h5\"),\n",
    "                                      save_weights_only=True,\n",
    "                                      monitor='val_loss',\n",
    "                                      mode='min',\n",
    "                                      save_best_only=True)\n",
    "\n",
    "# Fitting the model\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(val_images, val_masks),\n",
    "                    callbacks=[checkpoint_callback])\n",
    "\n",
    "# Visualizing the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Val loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Loading the best model weights\n",
    "model.load_weights(os.path.join(checkpoint_path, \"nebula_segmentation.h5\"))\n",
    "\n",
    "# Predicting the masks for test images\n",
    "test_masks = model.predict(test_images)\n",
    "\n",
    "# Saving the predicted masks\n",
    "output_path = \"/path/to/save/output\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "for i, img_name in enumerate(test_images):\n",
    "    masks = np.argmax(test_masks[i], axis=-1)\n",
    "    rle_masks = packages.maskToRle(masks)\n",
    "    df = pd.DataFrame({'im_id': [img_name], 'EncodedPixels': [rle_masks]})\n",
    "    df.to_csv(os.path.join(output_path, f\"mask_{img_name}.csv\"), index=False)\n",
    "\n",
    "print(\"Segmentation masks saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
