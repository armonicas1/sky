{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zVg6WM9DRso4"
      },
      "source": [
        "<div>\n",
        "<center>\n",
        "    <img src=\"https://datascientest.fr/train/assets/logo_datascientest.png\", style=\"height:150px\">\n",
        "</center> \n",
        "</div>\n",
        "\n",
        "<hr style=\"border-width:2px;border-color:##75DFC1\">\n",
        "<br>\n",
        "<center> <h1> Segmentation de régions nuageuses </h1> </center> <br><br>\n",
        "<center> <h2> Parties 3 - Segmentation </h2> </center> <br><br>\n",
        "<hr style=\"border-width:2px;border-color:##75DFC1\">\n",
        "\n",
        "<div class=\"panel\" style=\"border-width:2px;border-color:##75DFC1\"> \n",
        "    <div class=\"panel-body\">\n",
        "<h3> Contexte du sujet </h3>\n",
        "<p>Il s’agit d’analyser et d’identifier dans chaque image satellite les régions qui contiennent une formation nuageuse particulière (poisson, fleur, gravier, sucre). Ces segmentations aident à la projection climatique en permettant de démystifier une des variables importantes du climat.</p>\n",
        "        \n",
        "<h3>Data</h3>\n",
        "<p>Les données sont des images satellites labellisées, un set de donnée test non labellisé est disponible.<br>\n",
        "[Données Kaggle]<span style=\"color:#660099;\">\n",
        "    <a href=\"https://www.kaggle.com/c/understanding_cloud_organization/\">\n",
        "        https://www.kaggle.com/c/understanding_cloud_organization/</a></p> \n",
        "        </div>       \n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dnJAFdmwR6_2"
      },
      "source": [
        "### Groupe\n",
        "> * Cathy Baynaud-Samson,\n",
        "> * Yann Bernery\n",
        "> * José Castro\n",
        "> * Ludovic Changeon"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zqfyUEZnoLlL"
      },
      "source": [
        "## **1 - Import des librairies**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QNG6Dh7tYkon"
      },
      "source": [
        "La librairie du projet Nebula est chargée du master Github, avant l'import général."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH00ittI-aO6",
        "outputId": "f414c39a-82f3-4faa-e0f6-e61ed05a04a1"
      },
      "outputs": [],
      "source": [
        "# Création de répertoires pour stocker le Git, les librairies et checkpoints\n",
        "!mkdir nebulaTemp -p\n",
        "!mkdir packages -p\n",
        "\n",
        "# Copie des sources des librairies projet depuis le Github\n",
        "!git clone https://github.com/DataScientest/nebula/ ./nebulaTemp --dissociate\n",
        "\n",
        "# Répartition des différentes ressources dans les répertoires\n",
        "!cp ./nebulaTemp/packages/* ./packages\n",
        "\n",
        "# Suppression de la copie du repository source\n",
        "!rm nebulaTemp -r"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy4fORpalg_T"
      },
      "source": [
        "Initialisation de la variable d'environnement SM_FRAMEWORK, nécessaire à l'import du package segmentation_models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEPgKQna6zGT",
        "outputId": "3c65963a-2f61-46e2-a38e-a5fab851b0a4"
      },
      "outputs": [],
      "source": [
        "%env SM_FRAMEWORK=tf.keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhybrtzz6lPz",
        "outputId": "6b0536da-e7b2-4aed-b7b3-c1540a1892b0"
      },
      "outputs": [],
      "source": [
        "pip install segmentation_models"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qD4qRvBUlt23"
      },
      "source": [
        "Import des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCX67JJCoDCp"
      },
      "outputs": [],
      "source": [
        "# Import des librairies du projet\n",
        "import packages\n",
        "\n",
        "# Librairies génériques\n",
        "import os, glob\n",
        "from shutil import copyfile, unpack_archive\n",
        "import zipfile\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import argmax\n",
        "from copy import deepcopy\n",
        "from numpy.random import seed\n",
        "import requests\n",
        "\n",
        "# Librairies images/graphiques\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "import PIL\n",
        "from   PIL import Image\n",
        "import cv2\n",
        "from matplotlib import patches\n",
        "import seaborn as sns\n",
        "\n",
        "# Interface library machine learning\n",
        "import tensorflow as tf\n",
        "import multiprocessing\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from albumentations import Compose, VerticalFlip, HorizontalFlip, Rotate, RandomGamma \n",
        "from tensorflow.keras.optimizers import Nadam, RMSprop\n",
        "from tensorflow.keras import callbacks\n",
        "#from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "\n",
        "# Scikit Learn\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from skimage.measure import label, regionprops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install albumentations\n",
        "#!pip install --upgrade keras\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "l-MnZaEzl3Et"
      },
      "source": [
        "Installation et import du package segmentation_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2rS0enH5_vZ",
        "outputId": "27fcac3e-49ed-4e76-e7fe-cd7e5c0be9b9"
      },
      "outputs": [],
      "source": [
        "import segmentation_models as sm"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fBMRg-JxjY9t"
      },
      "source": [
        "## **2 - Import des données**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "33Qae0iAYzeT"
      },
      "source": [
        "Préalables :\n",
        "* Google Drive est connecté sous \"/content/drive/MyDrve\"\n",
        "* Le zip du dataset est disponible sur le Google Drive"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HyWicYTuoadn"
      },
      "source": [
        "Copie puis décompression du zip du dataset (environ 6 minutes)<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWTYP0W3DFFF",
        "outputId": "bc7b2668-a6b3-427e-d645-a450310d6ac9"
      },
      "outputs": [],
      "source": [
        "packages.copy_data_from_drive()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7KEznGXanvaA"
      },
      "source": [
        "Définition des répertoires :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIyVUpujnsoF"
      },
      "outputs": [],
      "source": [
        "#repTest  = 'test_images/'\n",
        "#repTrain = 'train_images/'\n",
        "repTest  = 'C:/-/-/-ds/-ds.cloud/archivetm/test_images/'\n",
        "repTrain = 'C:/-/-/-ds/-ds.cloud/archivetm/train_images/'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VaOgV2BRjlQi"
      },
      "source": [
        "Chargement du fichier train.csv :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "TnsfBkgen2WR",
        "outputId": "bbcb550b-d6cc-4cd2-d493-e0239207e2f4"
      },
      "outputs": [],
      "source": [
        "train = packages.load_train()\n",
        "train.head(5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EOnzBEr8_ooq"
      },
      "source": [
        "## **3 - Pre-traitement du dataset**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ADB91D65Lo_b"
      },
      "source": [
        "On définit tout d'abord quelques constantes utilisées tout au long de ce notebook.\n",
        "\n",
        "*Remarques sur la taille des images* :<br>\n",
        "Les images ont une taille d'origine de 1400 X 2100 pixels. Nous ne pouvons conserver cette taille à l'entrée de nos modèles, sous peine de manquer de mémoire. Nous allons réduire la dimension de nos images a 320 X 480. Cette taille a l'avantage de converser le ratio largeur / longueur de l'image, par ailleurs la largeur comme la longueur sont des multiples de 32.<br>\n",
        "La taille de soumission (350 X 525) est la taille des masques attendus par Kaggle, l'opération de réduction sera opérée lors de la préparation du fichier final de soumission.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_VR0gomwsFP"
      },
      "outputs": [],
      "source": [
        "target_size = (320, 480)                #Taille à laquelle les images seront redimensionnées a l'entrée du modele\n",
        "origin_size = (1400, 2100)              #Taille d'orgine des images\n",
        "submission_mask_size = (350, 525)       #Taille à laquelle les masques sont attendus par Kaggle (cf. partie Evaluation du projet sur Kaggle) \n",
        "nb_canaux = 3\n",
        "num_cores = multiprocessing.cpu_count()\n",
        "couleurs=[(0,0,255), (255,0,0), (0,255,0), (255,255,0)]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-u7zQOxtLyaj"
      },
      "source": [
        "On isole les labels et le nom des images en prenant soin de laisser les encodage RLE nuls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "i1_AysR4dd93",
        "outputId": "f7d4e59e-3870-4272-90d3-58510d2cbf55"
      },
      "outputs": [],
      "source": [
        "train = packages.label_parsing(train, drop_na=False)\n",
        "train.head(5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lxEGkWqIMYd5"
      },
      "source": [
        "Enfin, nous allons agréger les encodages RLE par image puis sur cette base initialiser un dictionnaire qui sera le principal vecteur de recherche des générateurs d'images lors de l'apprentissage des modèles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "T-u50AxTdLS6",
        "outputId": "8f7e9f09-cf55-4181-80d8-62da71af1369"
      },
      "outputs": [],
      "source": [
        "#Depuis le dataframe précédent on détermine la liste des classes ...\n",
        "formations_nuageuses = train['label'].unique()\n",
        "\n",
        "# ... ainsi que leur nombre\n",
        "nb_classes = len(formations_nuageuses)\n",
        "\n",
        "#On agrège les codes RLE par image pour les présenter en ligne\n",
        "train_transformed = pd.concat([train.set_index(['image']).groupby('label')['EncodedPixels'].get_group(key) for key in formations_nuageuses],axis=1)\n",
        "train_transformed.columns = formations_nuageuses\n",
        "train_transformed.reset_index(inplace=True)\n",
        "\n",
        "#Dernière étape du pré-traitement: on construit un dictionnaire à partir du dataframe précédent\n",
        "#Ceci va nous permettre d'accélérer l'accès aux codes RLE depuis l'image lors de la phase d'apprentissage du modèle \n",
        "index_classes = {image:rle for image, rle in zip(train_transformed['image'], train_transformed.iloc[:, 1:].values)}\n",
        "\n",
        "\n",
        "train_transformed.head(3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QYsPvhH0MkJS"
      },
      "source": [
        "## **4 - Générateur et traitement des images**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QNEQ-zOsMw2L"
      },
      "source": [
        "Nous avons opté pour la création d'un générateur personnalisé hérité de la classe Sequence. Ce choix est motivé par la possibilité offerte d'utiliser les albumentations en lieu et place des augmentations natives de tensorflow, et d'autre part, par la simplicité d'ajout de retraitement d'images.\n",
        "Le générateur offre la possibilité d'appliquer aux images, lors de l'apprentissage, les augmentations ci-dessous :\n",
        "\n",
        "- Symétrie horizontale\n",
        "- Symétrie verticale\n",
        "- Rotation dans la limite de 10 degrés\n",
        "- Correction gamma\n",
        "\n",
        "Les corrections gamma ont été choisies pour atténuer les stries solaires constatées sur certaines images.\n",
        "\n",
        "Par ailleurs il est possible d'activer deux options de pré-traitement des images :\n",
        "- le Test Time Augmentation (TTA) : cela concerne uniquement les prédictions faites sur la base d'un générateur. L'option consiste à appliquer une symétrie horizontale systématique a l'image. Il conviendra alors d'inverser la transformation sur les valeurs prédites puis d'effectuer une moyenne avec les valeurs issues d'une prédiction sans TTA.\n",
        "\n",
        "- la réduction de bruit : cette option va venir appliquer un masque aux images afin d'éliminer les pixels inférieurs a une certaine valeur de blanc. Il pourra être intéressant de pré-entrainer un modèle sur un nombre d'epochs limité afin de le faire travailler sur la forme des nuages, avant un apprentissage complet sans réduction de bruit. Ci-dessous l'illustration d'un masque de réduction de bruit (à gauche l'image d'origine, a droite l'image retraitée destinée a pratiquer un pré-apprentissage).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "nuZUk8viG5mc",
        "outputId": "a08d3605-c0d8-4df1-d6e2-d6a8be69eb62"
      },
      "outputs": [],
      "source": [
        "# Chargement d'une image de test\n",
        "img = load_img(os.path.join(repTrain, '7405a00.jpg'), target_size=target_size)\n",
        "im3 = np.array(img)\n",
        "image_gray = cv2.cvtColor(im3, cv2.COLOR_RGB2GRAY)\n",
        "# Filtrage\n",
        "(thresh, blackAndWhiteImage) = cv2.threshold(image_gray, 110, 255, cv2.THRESH_BINARY)\n",
        "img2 = cv2.bitwise_and(im3, im3, mask=blackAndWhiteImage)\n",
        "# Affichage\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 20), constrained_layout=True)\n",
        "ax[0].imshow(img) \n",
        "ax[1].imshow(img2) \n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UkQ4BUgaH3H6"
      },
      "source": [
        "Définition du générateur :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIls0W9pj2_O"
      },
      "outputs": [],
      "source": [
        "class MultiGenerator(tf.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, \n",
        "                 images_set, \n",
        "                 index_classes=None, \n",
        "                 base_path=repTrain,\n",
        "                 batch_size=32, \n",
        "                 image_size=origin_size, \n",
        "                 nb_canaux=3, \n",
        "                 reshape=None,\n",
        "                 augment=False, \n",
        "                 nb_classes=4, \n",
        "                 random_state=123, \n",
        "                 shuffle=True,\n",
        "                 tta_mode=False,\n",
        "                 preproc=[]):\n",
        "\n",
        "        self.images_set = images_set         #Liste d'images à générer \n",
        "        self.index_classes = index_classes   #Dictionnaire image/codes RLE\n",
        "        self.base_path = base_path           #Répertoire source                    \n",
        "        self.image_size = image_size         #Taille d'origine des images\n",
        "        self.reshape = reshape               #Taille cible des images         \n",
        "        self.batch_size = batch_size         #Taille du batch\n",
        "        self.nb_canaux = nb_canaux           #Nombre de canaux (3 ou 1)\n",
        "        self.augment = augment               #Augmentation à appliquer (O/N)\n",
        "        self.nb_classes = nb_classes         #Nombre de classes cibles\n",
        "        self.shuffle = shuffle               #Mélange aleatoire (O/N) \n",
        "        self.random_state = random_state     #Graine\n",
        "\n",
        "        self.tta_mode = tta_mode             #Test Time Augment. à appliquer (O/N)\n",
        "        #Info : Le TTA consiste ici en un flip horizontal de l'image\n",
        "\n",
        "        self.preproc = preproc               #Pré-processing des images\n",
        "        #Info : Le pré-processing peut accepter les valeurs suivantes :\n",
        "        # 'fnoise' : réduction du bruit par application d'un masque\n",
        "        #Les actions de pré-processing peuvent être cumulées\n",
        "\n",
        "        #Le mode TTA n'est disponible que lors d'une prédiction \n",
        "        if self.index_classes is not None:\n",
        "            self.tta_mode = False\n",
        "\n",
        "        #Le mode TTA et l'augmentation aléatoire sont incompatibles    \n",
        "        if self.tta_mode:\n",
        "            self.augment = False\n",
        "        \n",
        "        self.on_epoch_end()\n",
        "        np.random.seed(self.random_state)\n",
        "\n",
        "    ##  __len__\n",
        "    #  -------------------\n",
        "    #  On détermine le nombre de lots par epoch\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.images_set) / self.batch_size))\n",
        "\n",
        "    #Méthode : Constitution d'un lot\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        images_set_batch = [self.images_set[k] for k in indexes]\n",
        "        \n",
        "        X = self.__generate_X(images_set_batch)\n",
        "        \n",
        "        #Mode prédiction : l'index des classes n'a pas été spécifié\n",
        "        if self.index_classes == None:                    \n",
        "            return X  \n",
        "\n",
        "        #Mode apprentissage : l'index des classes a bien été spécifié\n",
        "        else:                                             \n",
        "            y = self.__generate_y(images_set_batch)\n",
        "            \n",
        "            if self.augment:\n",
        "                X, y = self.__augment_batch(X, y)\n",
        "            \n",
        "            return X, y\n",
        "\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        'Reindexation des lots'\n",
        "        self.indexes = np.arange(len(self.images_set))\n",
        "        if self.shuffle == True:\n",
        "            np.random.seed(self.random_state)\n",
        "            np.random.shuffle(self.indexes)\n",
        "    \n",
        "    def __generate_X(self, images_set_batch):\n",
        "        'Generation des features'\n",
        "        # Initialisation des features\n",
        "        if self.reshape is None:\n",
        "            X = np.empty((self.batch_size, *self.image_size, self.nb_canaux))\n",
        "        else:\n",
        "            X = np.empty((self.batch_size, *self.reshape, self.nb_canaux))\n",
        "        \n",
        "        # Génération des données depuis les images\n",
        "        for i, image_name in enumerate(images_set_batch):\n",
        "            img_path = f\"{self.base_path}/{image_name}\"\n",
        "            img = self.__load_rgb(img_path)\n",
        "            \n",
        "            #L'image est redimmensionnée si besoin\n",
        "            if self.reshape is not None:\n",
        "                img = packages.np_transposition(img, self.reshape)\n",
        "            \n",
        "            #TTA active : on réalise une symétrie horizontale de l'image\n",
        "            if self.tta_mode:\n",
        "                img = np.flip(img, axis=1)\n",
        "\n",
        "            X[i,] = img\n",
        "\n",
        "        return X\n",
        "    \n",
        "    def __generate_y(self, images_set_batch):\n",
        "        if self.reshape is None:\n",
        "            y = np.empty((self.batch_size, *self.image_size, self.nb_classes), dtype=int)\n",
        "        else:\n",
        "            y = np.empty((self.batch_size, *self.reshape, self.nb_classes), dtype=int)\n",
        "        \n",
        "        for i, image_name in enumerate(images_set_batch):\n",
        "            rles = self.index_classes[image_name]\n",
        "\n",
        "            if self.reshape is not None:\n",
        "                masks = packages.list_rleToMask(rles, input_shape=self.image_size, reshape=self.reshape)\n",
        "            else:\n",
        "                masks = packages.list_rleToMask(rles, input_shape=self.image_size)\n",
        "            \n",
        "            y[i, ] = masks\n",
        "\n",
        "        return y\n",
        "    \n",
        "    def __load_grayscale(self, img_path):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = img.astype(np.float32) / 255.\n",
        "        img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "        return img\n",
        "    \n",
        "    def __load_rgb(self, img_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if 'fnoise' in self.preproc:\n",
        "            image_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            (thresh, blackAndWhiteImage) = cv2.threshold(image_gray, 110, 255, cv2.THRESH_BINARY)\n",
        "            img = cv2.bitwise_and(img, img, mask=blackAndWhiteImage)\n",
        "\n",
        "        img = img.astype(np.float32) / 255.\n",
        "\n",
        "        return img\n",
        "    \n",
        "    ## albumentationApply \n",
        "    #  -------------------\n",
        "    #  On applique à l'image et au masque passé en paramètre\n",
        "    #  une série de transformations. \n",
        "\n",
        "    def __albumentationApply(self, img, masks):\n",
        "        transformations_pipline = Compose([\n",
        "            HorizontalFlip(),         #Symétrie horizontale\n",
        "            VerticalFlip(),           #Symétrie verticale\n",
        "            Rotate(limit=10),         #Rotation dans la limite de 10 degrés\n",
        "            RandomGamma()             #Correction gamma\n",
        "        ])\n",
        "        \n",
        "        transformations = transformations_pipline(image=img, mask=masks)\n",
        "        augmented_img   = transformations['image']\n",
        "        augmented_masks = transformations['mask']\n",
        "        \n",
        "        return augmented_img, augmented_masks\n",
        "    \n",
        "    def __augment_batch(self, img_batch, masks_batch):\n",
        "        for i in range(img_batch.shape[0]):\n",
        "            img_batch[i, ], masks_batch[i, ] = self.__albumentationApply(\n",
        "                img_batch[i, ], masks_batch[i, ])\n",
        "        \n",
        "        return img_batch, masks_batch"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t7ssTiYaO9Mo"
      },
      "source": [
        "## **5 - Implémentation d'un modèle de segmentation**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mX-HtUBkZoaA"
      },
      "source": [
        "Lors des essais préliminaires, les modèles personnels construits \"from scratch\" ne dépassant pas une précision de 0.55, il a été décidé de faire appel à des modèles plus conséquents."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9JmkLSlCnfOe"
      },
      "source": [
        "### **5.1 - Stratégie et architecture**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aDF3iNhlfLcX"
      },
      "source": [
        "Nous allons implémenter deux modèles. Ces deux modèles seront entrainés sur le même jeu de données, puis leurs prédictions respectives feront l'objet d'une moyenne pondérée. Afin de maximiser la précision de l'ensemble nous choisissons deux modèles à l'architecture éloignée (donc moins corrélée) l'une de l'autre.\n",
        "\n",
        "Nous avons opté pour un premier modèle basé sur une architecture \"Unet\" et un backbone \"resnet 18\". Le second modèle s'appuie quant à lui sur une architecture \"Linknet\" et un backbone \"efficient Net B1\".<br>\n",
        "Etant limité en mémoire, ces deux architectures présentent l'avantage de compter un nombre relativement restreint de paramètres.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0UNXa_wLjxo",
        "outputId": "62fb682f-a747-4f54-e59e-90140ade56eb"
      },
      "outputs": [],
      "source": [
        "model1 = packages.buildSegmentationModel1(sm, nb_classes, target_size, nb_canaux)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYnaB8BxMEKq",
        "outputId": "95ae3854-8cfb-4b08-bfec-6af39750271f"
      },
      "outputs": [],
      "source": [
        "model2 = packages.buildSegmentationModel2(sm, nb_classes, target_size, nb_canaux)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgmrp2eP3GmE"
      },
      "outputs": [],
      "source": [
        "#model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYpmhcvS0gHX"
      },
      "outputs": [],
      "source": [
        "#model2.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iENBShObnrPF"
      },
      "source": [
        "### **5.2 - Métriques et pertes**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VWtGxHAlbbNF"
      },
      "source": [
        "Les fonctions présentées dans ce chapitre sont utilisées via la librairie projet \"packages\".  \n",
        "Les codes simplifiés présentés ci-dessous se veulent pédagogiques afin de permettre au lecteur de disposer du minimum d'information nécessaire à une bonne compréhension du notebook."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HJnRHAzQbed9"
      },
      "source": [
        "#### **5.2.1 - Métriques**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CB2IcEuTbhbB"
      },
      "source": [
        "Deux métriques spécifiques aux problématiques de \"computer vision\" sont définies :  \n",
        "* Intersection over union (IoU) ou indice de Jaccard (<a href = \"https://fr.wikipedia.org/wiki/Indice_et_distance_de_Jaccard\">IoU</a> sur Wikipedia)\n",
        "* Coefficient de Dice (<a href=\"https://fr.wikipedia.org/wiki/Indice_de_S%C3%B8rensen-Dice\">Indice de Dice</a> sur Wikipedia).\n",
        "\n",
        "Ces deux métriques partent du même principe : comparer l'intersection et l'union de deux ensembles afin de quantifier leur corrélation :  \n",
        "* $IoU={|A\\cap B| \\over |A\\cup B|}$\n",
        "* $Dice={2|A\\cap B| \\over |A| + |B|}$"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ubdDuZrBbn2j"
      },
      "source": [
        "Codage de la métrique iou :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB_TmWeqbox1"
      },
      "outputs": [],
      "source": [
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
        "    union = K.sum(y_true,[1,2,3]) + K.sum(y_pred,[1,2,3]) - intersection\n",
        "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
        "    return iou"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_z2mkzp-bsyy"
      },
      "source": [
        "Codage de la métrique de Dice :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hu8k6xJvbvHV"
      },
      "outputs": [],
      "source": [
        "def dice(y_true, y_pred , classWeights = np.ones(4)):\n",
        "  inter = K.log(1. + y_true * y_pred) / K.log(2.)\n",
        "  num = K.mean(K.sum(inter,(2,1)),0)\n",
        "  denom = K.mean(K.sum(y_true,(2,1)) + K.sum(y_pred,(2,1)),0)\n",
        "  m= (2.*K.sum(num * classWeights) + K.epsilon()) / (K.sum(denom * classWeights) + K.epsilon())\n",
        "  return m"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5u9ACzYbx66"
      },
      "source": [
        "Notes :\n",
        "* Le codage de la métrique de Dice a été réalisé pour permettre d'utiliser la fonction en tant que perte pour l'entraînement des modèles.  \n",
        "* Les métriques ci-dessus sont définies pour des tenseurs de rang 4. Le codage dans la librairie projet \"packages\" intègre les rangs entre 1 et 4 pour la métrique de Dice. Ceci permet d'utiliser cette métrique sur tous types de tenseurs (1 : vecteurs, 2 : images individuelles, 3 : lots de quatre masques détectés pour une image, 4 : lots de masques détectés pour un lot d'images).\n",
        "* Afin de disposer d'un levier supplémentaire pour surveiller l'entraînement suivant la métrique de Dice, une pondération a été ajoutée sous forme d'un vecteur de quatre poids (classWeights) se référant aux quatre classes de notre problématique de segmentation."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ER3QMNYPb6E2"
      },
      "source": [
        "#### **5.2.2 - Pertes**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2afFAacYb9VJ"
      },
      "source": [
        "Deux pertes sont utilisées :\n",
        "* Binary_crossentropy qui fait partie des pertes pré-codées dans keras et qui fournit de très bons résultats.\n",
        "* DiceLoss : afin de tenter de changer de paradigme, une fonction de perte a été codée à partir du coefficient de Dice défini au chapitre métriques, ci-dessus."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oGsClJ-JcDrQ"
      },
      "source": [
        "La perte Binary Crossentropy est classique, on ne reviendra pas sur sa définition.  \n",
        "La perte DiceLoss est quant à elle définie à partir du coefficient de Dice (DiceCoeff) telle que :  \n",
        "<p align=\"center\">$DiceLoss(T_1, T_2) = 1 - DiceCoeff(T_1, T_2)$</p>   \n",
        "<p>Avec : $T_1$ et $T_2$ : deux tenseurs Tensorflow de rangs 4, à valeurs réelles comprises entre 0 et 1.</p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Dofw4FGMkYwU"
      },
      "source": [
        "### **5.3 - Compilation et apprentissage**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SgN84O96n7S3"
      },
      "source": [
        "**Fonctions de compilation et d'ajustement**\n",
        "\n",
        "Les fonctions de base comme les fonctions de compilation et d'ajustement ont fait l'objet de l'implémentation d'un wrapper destiné à surcharger les modèles de classification (phase 2) et de segmentation (phase 3)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jT5Sj9OHN2f1"
      },
      "source": [
        "**Fonction callbacks**\n",
        "\n",
        "Trois callbacks ont été définies dans les packages, la sauvegarde des poids du meilleur modèle en cours d'entraînement, la réduction sur palier du taux d'apprentissage de l'optimizer et enfin la fin prématurée de l'apprentissage si la perte stagne en validation. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cyyTbo2BoWG4"
      },
      "source": [
        "### **5.4 - Apprentissage des modèles**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fjT9ITEpkhc2"
      },
      "source": [
        "**Métriques communes :**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p7h1KBWykzsf"
      },
      "source": [
        "Nous allons monitorer les 2 modèles sur des métriques identiques. (cf point \"Métriques et pertes\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihAKBxUmf7Lj"
      },
      "outputs": [],
      "source": [
        "#Nous definissons pour les 2 modeles un pool de metriques communes\n",
        "classWeights = [1., 1., 1., 1.]\n",
        "dice_metrics = packages.diceMetric(classWeights=classWeights)\n",
        "metrics_pool = [packages.iou_coef, dice_metrics]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qeqIgoU8lIu3"
      },
      "source": [
        "**Réservation d'un set de test :**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EsE4N9XzlS3g"
      },
      "source": [
        "Afin de pouvoir établir des prédictions et des évaluations sur des images inconnues des modèles, et pour lesquelles nous connaissons les labels, nous mettons de côté 224 images du set d'apprentissage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZN_3kVDl4Jg"
      },
      "outputs": [],
      "source": [
        "test_size = 224\n",
        "data_collector, test_collector = packages.splitValid(train_transformed['image'], test_size=test_size)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "P_ayxBj_1Tgn"
      },
      "source": [
        "**Ajustement du modèle 1 :**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1SBuDDYDiB9U"
      },
      "source": [
        "Nous allons pour le premier modèle opérer un pré-apprentissage sur un nombre d'epochs réduit. Ce pré-apprentissage va s'effectuer non pas sur les images d'origine mais sur les images résultantes de l'application d'un masque destiné à filtrer les bruits. Notre objectif est de faciliter pour notre modèle la reconnaissance des formes des nuages et ainsi d'initialiser les poids pour l'apprentissage définitif.\n",
        "\n",
        "Nous ne spécifions pour ce pré-apprentissage aucun callback.\n",
        "L'optimizer retenu pour ce premier modèle est le Nadam. La fonction perte est un binary cross entropy (bce).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xeJrqnZLkMJ"
      },
      "outputs": [],
      "source": [
        "#Par défaut le preprocessing de reduction de bruit est désactivé\n",
        "m1pre_fnoise = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cSUSq9fLPBr",
        "outputId": "a42100a4-3a0c-4cce-d164-1424a3d08a1c"
      },
      "outputs": [],
      "source": [
        "#from packages.model_building import NebulaWrapper\n",
        "from packages.model_building import skyWrapper\n",
        "m1pre_fnoise = True\n",
        "\n",
        "# Hyperparamètres\n",
        "#-------------------------------\n",
        "batchSize = 32\n",
        "epochs         = 2            #le pré-apprentissage est lancé sur 5 epochs     \n",
        "learning_rate  = 0.0005       #Taux d'apprentissage de l'optimizer\n",
        "checkpointName = ''           #Nous ne sauvegardons pas les poids sur cette itération\n",
        "\n",
        "# Générateurs\n",
        "#-------------------------------\n",
        "train_imgs, val_imgs = packages.splitValid(data_collector)\n",
        "train_imgs = train_imgs.tolist()\n",
        "val_imgs = val_imgs.tolist()\n",
        "\n",
        "train_generator = MultiGenerator(train_imgs,\n",
        "                                index_classes=index_classes,\n",
        "                                batch_size=batchSize,\n",
        "                                reshape=target_size,\n",
        "                                augment=True,\n",
        "                                nb_canaux=nb_canaux,\n",
        "                                nb_classes=nb_classes,\n",
        "                                preproc=['fnoise'])\n",
        "\n",
        "val_generator = MultiGenerator(val_imgs,\n",
        "                                index_classes=index_classes,\n",
        "                                batch_size=batchSize, \n",
        "                                reshape=target_size,\n",
        "                                augment=False,\n",
        "                                nb_canaux=nb_canaux,\n",
        "                                nb_classes=nb_classes,\n",
        "                                preproc=['fnoise'])\n",
        "\n",
        "model1 = packages.buildSegmentationModel1(sm, nb_classes, target_size, nb_canaux)\n",
        "#m1Wrapper = packages.NebulaWrapper(model1, autoInit=False)\n",
        "m1Wrapper = packages.skyWrapper(model1, autoInit=False)\n",
        "#m1Wrapper = packages.model_building.NebulaWrapper(model1, autoInit=False)\n",
        "\n",
        "optimizer = Nadam(learning_rate=learning_rate)\n",
        "m1Wrapper.compile(optimizer, metrics=metrics_pool)\n",
        "history1p = m1Wrapper.fit(train_generator, validation_data=val_generator, epochs=epochs, callbacks = [], class_weight=None)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Puc5ILk4jHKK"
      },
      "source": [
        "Une fois le pré-apprentissage terminé, nous lançons l'apprentissage définitif de notre premier modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2R6xrj4sUwS",
        "outputId": "57d5ce65-7ab7-4f76-e8cb-2f00b9c00478"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Hyperparametres\n",
        "#-------------------------------\n",
        "batchSize = 32\n",
        "epochs         = 2                 #Nombre max d'epochs #40\n",
        "learning_rate  = 0.001              #Taux d'apprentissage de départ\n",
        "checkpointName = 'resnet18'         #Nom racine des fichiers de sauvegarde\n",
        "\n",
        "reducePatience = 3                   #nb d'epochs max après lequel on réduit le taux d'apprentissage\n",
        "                                     #si le val_loss ne s'améliore pas\n",
        "\n",
        "reduceFactor   = 0.05                #facteur de réduction du taux d'apprentissage\n",
        "\n",
        "earlyStopPatience = 7                #nb d'epochs max avant lequel on arrête l'apprentissage\n",
        "                                     #si le val_loss ne s'améliore pas\n",
        "\n",
        "# Générateurs\n",
        "#-------------------------------\n",
        "train_imgs, val_imgs = packages.splitValid(data_collector)\n",
        "train_imgs = train_imgs.tolist()\n",
        "val_imgs = val_imgs.tolist()\n",
        "\n",
        "train_generator = MultiGenerator(train_imgs,\n",
        "                                index_classes=index_classes,\n",
        "                                batch_size=batchSize,\n",
        "                                reshape=target_size,\n",
        "                                augment=True,\n",
        "                                nb_canaux=nb_canaux,\n",
        "                                nb_classes=nb_classes)\n",
        "\n",
        "val_generator = MultiGenerator(val_imgs,\n",
        "                                index_classes=index_classes,\n",
        "                                batch_size=batchSize, \n",
        "                                reshape=target_size,\n",
        "                                augment=False,\n",
        "                                nb_canaux=nb_canaux,\n",
        "                                nb_classes=nb_classes)\n",
        "\n",
        "if not m1pre_fnoise:\n",
        "    model1 = packages.buildSegmentationModel1(sm, nb_classes, target_size, nb_canaux)\n",
        "    #m1Wrapper = packages.NebulaWrapper(model1, autoInit=False)\n",
        "    m1Wrapper = packages.skyWrapper(model1, autoInit=False)\n",
        "    optimizer = Nadam(learning_rate=learning_rate)\n",
        "    m1Wrapper.compile(optimizer, metrics=metrics_pool)\n",
        "\n",
        "# Définition des callbacks à appliquer pendant l'apprentissage\n",
        "lstCallbacks = [packages.cb_earlyStopping(patience = earlyStopPatience),\n",
        "                packages.cb_modelCheckPoint(checkpointName),  \n",
        "                packages.cb_reduceLr(patience =reducePatience, factor = reduceFactor)]\n",
        "\n",
        "history1 = m1Wrapper.fit(train_generator, validation_data=val_generator, epochs=epochs, callbacks = lstCallbacks, class_weight=None)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gf1H6x8xeimv"
      },
      "source": [
        "**Ajustement du modèle 2 :**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SEgwKyhhjoe6"
      },
      "source": [
        "Le second modèle ne fait l'objet que d'un cycle d'apprentissage. \n",
        "\n",
        "L'optimizer retenu est RMSProp, la fonction perte est un Dice personnalisé, dont les détails sont donnés dans la partie \"Métriques et pertes\" de ce notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhUrJPYC1yZi",
        "outputId": "e47af5e9-0709-4e8c-ed4c-e795ba8df995"
      },
      "outputs": [],
      "source": [
        "# Hyperparamètres\n",
        "#-------------------------------\n",
        "batchSize = 18\n",
        "epochs         = 2                  #av 30Nombre max d'epochs\n",
        "learning_rate  = 0.001               #Taux d'apprentissage de départ\n",
        "checkpointName = 'efficientnetb1'    #Nom racine des fichiers de sauvegarde\n",
        "\n",
        "reducePatience = 3                   #nb d'epochs max après lequel on réduit le taux d'apprentissage\n",
        "                                     #si le val_loss ne s'améliore pas\n",
        "\n",
        "reduceFactor   = 0.05                #av 0.08 facteur de réduction du taux d'apprentissage\n",
        "\n",
        "earlyStopPatience = 6                #av 6 nb d'epochs max après lequel on arrête l'apprentissage\n",
        "                                     #si le val_loss ne s'améliore pas\n",
        "\n",
        "# Générateurs\n",
        "#-------------------------------\n",
        "train_imgs, val_imgs = packages.splitValid(data_collector)\n",
        "train_imgs = train_imgs.tolist()\n",
        "val_imgs = val_imgs.tolist()\n",
        "\n",
        "train_generator = MultiGenerator(train_imgs,\n",
        "                                index_classes=index_classes,\n",
        "                                batch_size=batchSize,\n",
        "                                reshape=target_size,\n",
        "                                augment=True,\n",
        "                                nb_canaux=nb_canaux,\n",
        "                                nb_classes=nb_classes)\n",
        "\n",
        "val_generator = MultiGenerator(val_imgs,\n",
        "                                index_classes=index_classes,\n",
        "                                batch_size=batchSize, \n",
        "                                reshape=target_size,\n",
        "                                augment=False,\n",
        "                                nb_canaux=nb_canaux,\n",
        "                                nb_classes=nb_classes)\n",
        "\n",
        "\n",
        "\n",
        "# Définition des callbacks à appliquer pendant l'apprentissage\n",
        "lstCallbacks = [packages.cb_earlyStopping(patience = earlyStopPatience),\n",
        "                packages.cb_modelCheckPoint(checkpointName),  \n",
        "                packages.cb_reduceLr(patience =reducePatience, factor = reduceFactor)]\n",
        "\n",
        "model2 = packages.buildSegmentationModel2(sm, nb_classes, target_size, nb_canaux)\n",
        "#m2Wrapper = packages.NebulaWrapper(model2, autoInit=False)\n",
        "m2Wrapper = packages.skyWrapper(model2, autoInit=False)\n",
        "classWeights = [1., 1., 1., 1.]\n",
        "m2_loss    = packages.diceLoss(name='diceL', classWeights=classWeights)\n",
        "optimizer = RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "m2Wrapper.compile(optimizer, loss=[m2_loss], metrics=metrics_pool)\n",
        "history2 = m2Wrapper.fit(train_generator, validation_data=val_generator, epochs=epochs, callbacks = lstCallbacks, class_weight=None)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oagBRVsTq1uq"
      },
      "source": [
        "### **5.5 - Chargement des modèles**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ColZKRG4qvH6"
      },
      "source": [
        "#### **5.5.1 - Import des fichiers poids**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rcAsRofUo-K7"
      },
      "source": [
        "Les poids des modèles sont téléchargeables depuis un drive, dont les liens sont prédéfinis ci-dessous. Il faut au préalable installer et importer la librairie gdown.\n",
        "\n",
        "Les poids sont également, si besoin, disponibles sous la forme d'un dataset hébergé sur le serveur Kaggle. Ils sont téléchargeables manuellement a l'adresse : <a href=\"https://www.kaggle.com/dataset/a4aa98fe1f1daf12d45c66cea8f6790a437767ce0260adbf64b51afafa462189\">Nebula Segmentation Weight</a> ou de manière automatique via le code indiqué plus bas. Il faut noter que dans ce dernier cas, d'une part un token d'authentification sera nécessaire et, d'autre part, il sera nécessaire d'installer l'API Kaggle."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pg-zzjreqUMi"
      },
      "source": [
        "***Import depuis Google Drive***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNlvPQBNPuS7",
        "outputId": "61fa630d-e1ab-4c35-8563-5baeacddf9bf"
      },
      "outputs": [],
      "source": [
        "pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59f3-2nmQXHa"
      },
      "outputs": [],
      "source": [
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz7xo1rNPw25"
      },
      "outputs": [],
      "source": [
        "def getWeightFromLink(url, output_file):\n",
        "    gdown.download(url, output_file, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEMDiKAMQtIb",
        "outputId": "b61baec6-9cf0-4773-f02c-1452287f4f67"
      },
      "outputs": [],
      "source": [
        "getWeightFromLink('https://drive.google.com/uc?id=1xUloap3iXApjf0Gz4qefWgnMpbLDpdqS', 'resnet18n.index')\n",
        "getWeightFromLink('https://drive.google.com/uc?id=1JRrKMxyQ3R4liPbhg0pp0AAWiUruzjyr', 'resnet18n.data-00000-of-00001')\n",
        "getWeightFromLink('https://drive.google.com/uc?id=1DzUDrmMHZ-Z69P2k5gmB3l6ls_lFa4k4', 'efficientnetb1n.index')\n",
        "getWeightFromLink('https://drive.google.com/uc?id=14bk-9aDeQ8RbQGI1CN8UpuHTLe2NdQEb', 'efficientnetb1n.data-00000-of-00001')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LQR4_3fJrG37"
      },
      "source": [
        "***Import depuis Kaggle***"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sdWT4kbmrdRQ"
      },
      "source": [
        "*Veuillez décommenter et executer les lignes suivantes si l'import depuis Google Drive a échoué.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8-UR3gZ5WN3",
        "outputId": "363d6ba1-3bec-46c8-db31-21c3526ae30f"
      },
      "outputs": [],
      "source": [
        "#!pip install -q kaggle\n",
        "#!mkdir -p ~/.kaggle\n",
        "#!cp kaggle.json ~/.kaggle/\n",
        "#!ls ~/.kaggle\n",
        "#!chmod 600 /root/.kaggle/kaggle.json  # set permission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxoez7L-4tjS",
        "outputId": "c8ee836f-598d-44a4-d7f1-19fcc245faa0"
      },
      "outputs": [],
      "source": [
        "#!kaggle datasets download -d ludovicchangeon/nebulasegmentationweights\n",
        "#unpack_archive('nebulasegmentationweights.zip')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z43MjP_q3ap"
      },
      "source": [
        "#### **5.5.2 - Chargement des modèles**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eqbaNRMTJKC"
      },
      "source": [
        "**Chargement du modèle 1 :**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBkPwNW5LHc0",
        "outputId": "7754e6cf-ebe3-4c1f-b01b-0c29cfc2924a"
      },
      "outputs": [],
      "source": [
        "chkpt_segm1 = 'resnet18n'\n",
        "#m1Wrapper = packages.NebulaWrapper(model1, autoInit=False)\n",
        "m1Wrapper = packages.skyWrapper(model1, autoInit=False)\n",
        "m1Wrapper.load_weights(chkpt_segm1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mx5UvvTPr0YK"
      },
      "source": [
        "**Chargement du modèle 2 :**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsmFXTFfA8mn",
        "outputId": "9d9b5815-dcab-452b-e6b7-b289c4f377cc"
      },
      "outputs": [],
      "source": [
        "chkpt_segm2 = 'efficientnetb1n'\n",
        "#m2Wrapper = packages.NebulaWrapper(model2, autoInit=False)\n",
        "m2Wrapper = packages.skyWrapper(model2, autoInit=False)\n",
        "m2Wrapper.load_weights(chkpt_segm2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0VDgFEKToMZ_"
      },
      "source": [
        "## **6 - Evaluation de l'apprentissage**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xEW0NVdLIVla"
      },
      "source": [
        "### **6.1 - Accuracy et loss par epoch**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tKcOByLMGy5Y"
      },
      "source": [
        "Modèle 1 : Evolution de la perte et de l'accuracy par epoch "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "CK3gRK3dTbPd",
        "outputId": "6fd180c2-487b-4f45-d4ef-b2ef89ce984f"
      },
      "outputs": [],
      "source": [
        "def plotFitting(history):\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5), constrained_layout=True)\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "  \n",
        "    hiou = history.history['iou_coef']\n",
        "    val_iou = history.history['val_iou_coef']\n",
        "\n",
        "    hdice = history.history['diceM']\n",
        "    val_dice = history.history['val_diceM']\n",
        "\n",
        "    epochs_range = range(len(loss))\n",
        "\n",
        "    ax[0].plot(epochs_range, loss, label='Training Loss')\n",
        "    ax[0].plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    ax[0].legend(loc='upper right')\n",
        "    ax[0].set_title(\"Evolution de la perte / Loss = \" + str(np.round(val_loss[-1], 4)))  \n",
        "    ax[0].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "\n",
        "    ax[1].plot(epochs_range, hiou, label='Training IOU')\n",
        "    ax[1].plot(epochs_range, val_iou, label='Validation IOU')\n",
        "    ax[1].plot(epochs_range, hdice, label='Training DICE')\n",
        "    ax[1].plot(epochs_range, val_dice, label='Validation DICE')\n",
        "    ax[1].legend(loc='lower right')\n",
        "    ax[1].set_title(\"Evolution de l'accuracy \" +\n",
        "                    \" / IOU = \" + str(np.round(val_iou[-1], 4)) + \n",
        "                    \" / DICE = \" + str(np.round(val_dice[-1], 4)))  \n",
        "    ax[1].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    plt.show()\n",
        "\n",
        "#Modele 1 : évolution de la perte et de l'accuracy\n",
        "plotFitting(history1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z-CI_W6EHEDA"
      },
      "source": [
        "Modèle 2 : Evolution de la perte et de l'accuracy par epoch "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "8BH8v1YmZ7R9",
        "outputId": "598a3727-15ef-4500-b4ed-89c475eab302"
      },
      "outputs": [],
      "source": [
        "#Modèle 2 : évolution de la perte et de l'accuracy\n",
        "plotFitting(history2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ttyP4QQHIdgI"
      },
      "source": [
        "### **6.2 - Précisions par classe**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "13hRwbveIhcf"
      },
      "source": [
        "Nous évaluons à présent, sur la base des 224 images que nous avons mises de côté et via une même métrique, la précision des deux modèles pour chacune des quatre classes de nuages. L'idée ici est uniquement de comparer les deux modèles sur chaque classe et via une métrique identique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "182qBt7uJSWZ"
      },
      "outputs": [],
      "source": [
        "test_imgs = test_collector.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLGUQXTvJii-"
      },
      "outputs": [],
      "source": [
        "#Sauvegarde des masques d'origine\n",
        "testS = []\n",
        "for image in test_imgs:\n",
        "    lstImg = []\n",
        "    lstImg.append(image)\n",
        "    ltMasks = packages.list_rleToMask(index_classes[image], input_shape=origin_size, reshape=target_size)\n",
        "    lstImg.append(ltMasks)\n",
        "    testS.append(lstImg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETh2tF0cJ7wM"
      },
      "outputs": [],
      "source": [
        "#Constitution du générateur temoin\n",
        "batchSize = 32\n",
        "test_generator = MultiGenerator(test_imgs,\n",
        "                              batch_size=batchSize, \n",
        "                              reshape=target_size,\n",
        "                              augment=False,\n",
        "                              shuffle=False,\n",
        "                              nb_canaux=nb_canaux,\n",
        "                              nb_classes=nb_classes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fcNZ9v60gqUJ"
      },
      "source": [
        "Nous établissons une estimation de la précision par classe sur la base d'une série restreintes d'images d'une part et selon des seuils d'activation par défaut. Les seuils d'activation plus précis seront établis par classe dans la suite de ce notebook (cf point \"Activation des pixels\" ci-dessous pour plus de détails)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qn520L491QV"
      },
      "outputs": [],
      "source": [
        "maskSeuils   = [.5, .5, .5, .5]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jV9PgLpWCbqH"
      },
      "source": [
        "Fonction commune de confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBJMJjCaCeNN"
      },
      "outputs": [],
      "source": [
        "def confusion(trueLabel, predictions):\n",
        "    #Confusion des masques d'origine et des prédictions du modèle 1\n",
        "    listAcc = [[] for i in range(len(formations_nuageuses))]\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        for k in range(len(formations_nuageuses)):\n",
        "            maskSource = (trueLabel[i][1])[:,:,k]\n",
        "            (thresh, imgFiltered) = cv2.threshold(predictions[i,:,:,k],\n",
        "                                              maskSeuils[k], 1,\n",
        "                                              cv2.THRESH_BINARY)\n",
        "            listAcc[k].append(packages.dice(maskSource, imgFiltered).numpy())\n",
        "\n",
        "    #Edition des résultats par classe\n",
        "    for k in range(4):\n",
        "        print(formations_nuageuses[k], ' -> ', np.mean(listAcc[k]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OX6zHQ7SKr9s"
      },
      "source": [
        "Modèle 1 : Evaluation de la précision par classe de nuages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmQfiYeCuHsx",
        "outputId": "72fda47f-00fe-41e2-f950-31bb7a1308b3"
      },
      "outputs": [],
      "source": [
        "#Prédictions des zones nuageuses / modèle 1\n",
        "prediction_masks1 = model1.predict(test_generator, workers=1, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sS-9qzSqDHvn",
        "outputId": "fdcbc507-166d-47fb-ec8a-9debc598f34d"
      },
      "outputs": [],
      "source": [
        "#Confusion des masques d'origine et des prédictions du modèle 1\n",
        "confusion(testS, prediction_masks1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ShN9W50LLRas"
      },
      "source": [
        "Modèle 2 : Evaluation de la précision par classe de nuages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWWf29YywzGp",
        "outputId": "1d36da6f-0d3b-4e3b-fbdd-34582c27e7c6"
      },
      "outputs": [],
      "source": [
        "#Prédictions des zones nuageuses / modèle 2\n",
        "prediction_masks2 = model2.predict(test_generator, workers=1, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bPdirofD9Mn",
        "outputId": "223566ac-f5d0-4bbf-e88c-6a094e033c0d"
      },
      "outputs": [],
      "source": [
        "#Confusion des masques d'origine et des prédictions du modèle 2\n",
        "confusion(testS, prediction_masks2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lLHJqvFjLn-Z"
      },
      "source": [
        "On peut constater que les deux modèles sont très proches, tous deux sont plus aptes à déceler les zones issues de la classe Fleur. Sur ce set en particulier le modèle 1 semble plus performant sur les classes Poisson et Sucre, le modèle 2 sur les classes Fleur et Gravier."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3rUp2zgYo0CJ"
      },
      "source": [
        "## **7 - Prédictions et soumission Kaggle**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8z5TbmG2o_SJ"
      },
      "source": [
        "### **7.1 - Prédictions des images de test**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "54RShLL3azbB"
      },
      "source": [
        "Nous commençons par lister les images à soumettre."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf8AwPhioSob"
      },
      "outputs": [],
      "source": [
        "#On prépare un dataframe des images à prédire au format attendu lors de la soumission \n",
        "df_sub = pd.read_csv('sample_submission.csv')\n",
        "df_sub['image'] = df_sub['Image_Label'].apply(lambda x: x.split('_')[0])\n",
        "    \n",
        "#... ainsi que la liste des images à prédire\n",
        "sub_imgs = df_sub['image'].unique().tolist()   "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ML61pRLIflsz"
      },
      "source": [
        "Nous procédons ensuite aux prédictions puis à la formation de l'ensemble. La détermination des prédictions finales va se dérouler en 4 étapes :\n",
        "- nous effectuons les prédictions sur le lot courant via le premier modèle,\n",
        "- nous faisons de même avec le second modèle,\n",
        "- nous déroulons un Test Time Augmentation avec le second modèle,\n",
        "- nous établissons enfin tout d'abord la moyenne arithmétique des prédictions du modèle 2 (avec et sans TTA) puis une moyenne arithmétique du résultat avec les prédictions du modèle 1.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGMTUW-tt-ec",
        "outputId": "a7f86d42-d791-448e-dea4-df6c9e4134b3"
      },
      "outputs": [],
      "source": [
        "#Pour éviter les dépassements mémoire, on découpe notre set de soumission en mini-lots \n",
        "sub_pred = []\n",
        "taille_chunk = 50 \n",
        "\n",
        "currentLot = 0\n",
        "\n",
        "sub_batch = [sub_imgs[i * taille_chunk:(i + 1) * taille_chunk] for i in range((len(sub_imgs) + taille_chunk - 1) // taille_chunk )]  \n",
        "indice = True\n",
        "for lot in sub_batch:\n",
        "\n",
        "    currentLot += 1\n",
        " \n",
        "    sub_generator  = MultiGenerator(lot,\n",
        "                              batch_size = 1, \n",
        "                              image_size = submission_mask_size,\n",
        "                              reshape = target_size,\n",
        "                              base_path = repTest,\n",
        "                              augment = False,\n",
        "                              shuffle = False,\n",
        "                              nb_canaux = nb_canaux,\n",
        "                              nb_classes = nb_classes)\n",
        "\n",
        "    tta_generator  = MultiGenerator(lot,\n",
        "                              batch_size = 1, \n",
        "                              image_size = submission_mask_size,\n",
        "                              reshape = target_size,\n",
        "                              base_path = repTest,\n",
        "                              augment = False,\n",
        "                              shuffle = False,\n",
        "                              nb_canaux = nb_canaux,\n",
        "                              nb_classes = nb_classes,\n",
        "                              tta_mode = True)\n",
        "    \n",
        "    print(\"Lot {} etape 1/4 : Prediction du modele 1\".format(currentLot))\n",
        "    lot_pred1 = model1.predict(sub_generator, workers=1, verbose=1)      #Prédictions du modèle 1\n",
        "\n",
        "    print(\"Lot {} etape 2/4 : Prediction du modele 2\".format(currentLot))\n",
        "    lot_pred2_sub = model2.predict(sub_generator, workers=1, verbose=1)      #Prédictions du modèle 2\n",
        "\n",
        "    print(\"Lot {} etape 3/4 : Test Time augmentation sur le modele 2\".format(currentLot))\n",
        "    lot_pred2_tta = model2.predict(tta_generator, workers=1, verbose=1)      #Prédictions TTA du modèle 2\n",
        "    lot_pred2_tta = np.flip(lot_pred2_tta, axis = 2)                               #Inversion de la transformation\n",
        "\n",
        "    print(\"Lot {} etape 4/4 : Moyenne de l'ensemble\".format(currentLot))\n",
        "    lot_pred2 = np.average(np.array([lot_pred2_sub, lot_pred2_tta ]), axis=0, weights=[1, 1])\n",
        "    lot_pred = np.average(np.array([lot_pred1, lot_pred2 ]), axis=0, weights=[1, 1])\n",
        "\n",
        "    sub_pred.append(lot_pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SrLll6pppEk4"
      },
      "source": [
        "### **7.2 - Post-traitement des prédictions**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YdfVOYimpXML"
      },
      "source": [
        "#### **7.2.1 - Présentation**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oibbXtYas-WX"
      },
      "source": [
        "Nous avons effectué plusieurs constats lors de la phase 1 :\n",
        "-\tla proportion de blanc des zones nuageuses varie selon la classe,\n",
        "-\tla superficie des zones nuageuses varie également\n",
        "\n",
        "Ceci nous incite à effectuer deux traitements sur les masques prédits par notre ensemble de modèles :\n",
        "-\til nous faut faire varier le seuil d'activation des pixels selon la classe. Les classes Gravel et Sugar présentent en effet à des niveaux distincts un pattern plus clairsemé, par conséquent laisser le seuil a 0.5 reviendrait à éliminer un grand nombre de pixels qui pourtant font partie de la zone nuageuse.\n",
        "-\tsur la base de la nouvelle zone couverte, il nous faut éliminer les masques dont la superficie est inférieure a une limite théorique associée à la classe courante\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDKDxZLfwTmz"
      },
      "source": [
        "#### **7.2.2 - Activation des pixels**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qA4wXX23Ohx1"
      },
      "source": [
        "Ci-dessous une étude sur l'incidence d'un seuil d'activation différent sur une même prédiction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "OAwv249PopMh",
        "outputId": "e71a4cd3-b3d0-4182-d818-86ace1eb057b"
      },
      "outputs": [],
      "source": [
        "#Test de seuil de masque sur la première image\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 5), constrained_layout=True)\n",
        "fig.suptitle(\"Incidence du seuil d'activation sur une même prédiction\", fontsize=16)\n",
        "\n",
        "lot = sub_pred[0]\n",
        "image_indice = 3\n",
        "pred_masks1 = cv2.threshold(lot[image_indice, :, :, 3], 0.5, 1, cv2.THRESH_BINARY)[1]\n",
        "im1 = plt.imread(os.path.join(repTest, sub_imgs[0]))\n",
        "\n",
        "packages.trace_boundingBox(im1, packages.np_transposition(pred_masks1, origin_size), color=(255, 255, 0))\n",
        "ax1.imshow(im1) \n",
        "ax1.set_title(\"Seuil d'activation = 0.5 \\n Superficie = \" + str(pred_masks1.sum()))\n",
        "                \n",
        "pred_masks2 = cv2.threshold(lot[image_indice, :, :, 3], 0.3, 1, cv2.THRESH_BINARY)[1]\n",
        "im2 = plt.imread(os.path.join(repTest, sub_imgs[0]))\n",
        "\n",
        "packages.trace_boundingBox(im2, packages.np_transposition(pred_masks2, origin_size), color=(255, 255, 0))\n",
        "ax2.imshow(im2)  \n",
        "ax2.set_title(\"Seuil d'activation = 0.3 \\n Superficie = \" + str(pred_masks2.sum()))\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a1_Qh9YV_4DH"
      },
      "source": [
        "A gauche le seuil d'activation est à 0.5, il s'agit du seuil par défaut, qui aurait par exemple était appliqué lors d'une simple conversion de la probabilité du pixel en entier. A droite, le seuil a été placé a 0.3<br>\n",
        "On constate une incidence dans la superficie de la zone couverte, il s'agit donc d'un paramètre à ne pas négliger.\n",
        "\n",
        "Nous pouvons rapprocher cette notion de la proportion de blanc déterminée par classe de nuage lors de la phase 1 :\n",
        "-\tFish : 30 %\n",
        "-\tFlower : 30 %\n",
        "-\tGravel : 20 %\n",
        "-\tSugar : 13%\n",
        "\n",
        "Afin de déterminer les seuils optimaux à appliquer nous allons procéder par échantillonnage du set d'apprentissage en mini-lot de 64 images. Chaque prédiction sera evaluée, par classe, via la métrique DICE sur une trentaine de lots au total. Une moyenne par classe sera au final établie.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-qgY0ynW3Nqi"
      },
      "source": [
        "**Détermination des seuils optimaux par échantillonnage** "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NdHmUIzy3eAy"
      },
      "source": [
        "On définit une fonction qui va venir balayer les seuils d'activation des pixels de chaque classe afin de déterminer le niveau de précision optimal sur l'ensemble de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFWUII1T3ink"
      },
      "outputs": [],
      "source": [
        "def thresholdSweep(y_true, y_pred,\n",
        "                   init = (9, 100, 10),\n",
        "                   refreshSteps = 5, zoom = 0.1,\n",
        "                   classWeights = [1.]*4, \n",
        "                   verbose = 0):\n",
        "  '''\n",
        "    Principe : Recherche d'un seuil de filtrage optimal\n",
        "    Objectif : Optimiser la moyenne des précisions sur l'ensemble de test.\n",
        "\n",
        "    Entrées:\n",
        "      y_pred : y_pred = model.predict(iterTest) => [batch, x, y, masks]\n",
        "            ex: pour accéder au masque de l'image 0 et de la classe 1 : y_pred[0, :, :, 1]\n",
        "      y_true : [batch, x, y, masks]\n",
        "      init : (min, max, step) trois paramètres définissant l'intervalle de recherche initial\n",
        "      classWeights : [1., 1., 1., 1.] pour la précision complète,\n",
        "                    annuler les indices des classes dont on ne veut pas\n",
        "      verbose : 0= pas de sortie texte ; plus verbose est grand, plus grand le nb de sorties (max = 2)\n",
        "      zoom : facteur appliqué au pas de recherche entre chaque itération\n",
        "    Sorties :\n",
        "      x : liste de tous les seuils testés\n",
        "      y : liste des précisions obtenues pour chacun des seuils\n",
        "  '''\n",
        "  # Initialisation des paramètres d'entrée\n",
        "  x, y = [], []               # Vecteurs de sortie\n",
        "  min, max, step = init       # Intervalle initial de recherche (0.09, 1.) avec step de balayage initial (0.1)\n",
        "  etapes = refreshSteps       # Nb de de zooms successifs\n",
        "  pred = y_pred               # Prédictions de masks sous la forme [batch, tx, ty, mask]\n",
        "  classWeights = classWeights # Poids sur chacune des classes\n",
        "\n",
        "  if verbose >0: print(f'Recherche sur l\\'intervalle : {init}\\n.   Poids de recherche : {classWeights}\\n.    Nb étapes : {etapes} / Reduction : {diminution}')\n",
        "  #\n",
        "  # Boucle 1 : nombre successifs de zooms de la précision\n",
        "  for optim in range(etapes):\n",
        "    if verbose >1 :\n",
        "      print(f'Step {optim+1} / {etapes}')\n",
        "      print(f'.  min / max : {min/100:0.4f} / {max/100:0.4f}')\n",
        "    #\n",
        "    # Boucle 2 : balayage entre min et max via step\n",
        "    for s in np.arange(min,max,step):\n",
        "      listeRes = []\n",
        "      seuil = [s/100]*4\n",
        "      #\n",
        "      # Boucle 3 : on applique la précision sur chacune des images de l'ensemble de test\n",
        "      for i in range(pred.shape[0]):\n",
        "        moyenne=[]\n",
        "        #\n",
        "        # Boucle 4 : on réalise le calcul pour chacune des classes\n",
        "        for k in range(4):\n",
        "          if classWeights[k]==0: # si la classe observée est pondérée à 0, inutile de faire le travail\n",
        "            moyenne.append(0)\n",
        "            continue\n",
        "          srcFiltered = (y_true[i][1])[:,:,k]\n",
        "          # Filtrage de la prédiction\n",
        "          (thresh, imgFiltered) = cv2.threshold(pred[i,:,:,k],\n",
        "                                                seuil[k], 1,\n",
        "                                                cv2.THRESH_BINARY)\n",
        "          moyenne.append(packages.dice(srcFiltered,\n",
        "                              imgFiltered,\n",
        "                              classWeights = classWeights).numpy()) # calcul de la précision et ajout dans la liste \"moyenne\"\n",
        "        listeRes.append(np.sum(moyenne*np.array(classWeights))/np.sum(classWeights)) # calcul de la moyenne de précision par image\n",
        "\n",
        "      y.append(np.mean(listeRes))\n",
        "      x.append(s)\n",
        "    xMax = x[y.index(np.max(y))] # calcul du seuil de précision maxi\n",
        "\n",
        "    if verbose >1 : print(f'.  acc : {np.max(y):0.5f}')\n",
        "\n",
        "    # Calcul des paramètres de la prochaine itération\n",
        "    min = np.max([xMax - step,1])        # on se recentre au niveau de la précision maxi\n",
        "    max = np.min([xMax + 1.5*step,100-K.epsilon()*10]) # on balaie entre +/- step\n",
        "    step = step * zoom             # à chaque étape on applique un facteur de zoom constant\n",
        "  #\n",
        "  # Affichage des meilleurs paramètres (précision @ seuil)\n",
        "  if verbose >0 : print(f'Prédiction maxi : {np.max(y):0.5f} @ {x[y.index(np.max(y))]:0.5f}')\n",
        "  return x,y"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-hWsGpfWg3bQ"
      },
      "source": [
        "On effectue ensuite un échantillonnage du set d'apprentissage (30 lots de 64 images chacun)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzz2ZfowwE0O",
        "outputId": "583fab44-a3f1-4b74-c67a-44455980c8d3"
      },
      "outputs": [],
      "source": [
        "accFit = []\n",
        "accSeuils = []\n",
        "\n",
        "for iteration in range(30):\n",
        "    np.random.seed(seed=None)\n",
        "    test_size = 64\n",
        "    data_collector, seuils_collector = packages.splitValid(train_transformed['image'], test_size=test_size, randomState=None)\n",
        "    \n",
        "    test_imgs = seuils_collector.tolist()\n",
        "    testS = []\n",
        "    for image in test_imgs:\n",
        "        lstImg = []\n",
        "        lstImg.append(image)\n",
        "        ltMasks = packages.list_rleToMask(index_classes[image], input_shape=origin_size, reshape=target_size)\n",
        "        lstImg.append(ltMasks)\n",
        "        testS.append(lstImg)\n",
        "\n",
        "    test_generator = MultiGenerator(test_imgs,\n",
        "                              batch_size=32, \n",
        "                              reshape=target_size,\n",
        "                              augment=False,\n",
        "                              shuffle=False,\n",
        "                              nb_canaux=nb_canaux,\n",
        "                              nb_classes=nb_classes)  \n",
        "    \n",
        "    y_pred = model1.predict(test_generator)\n",
        "    y_true = testS\n",
        "    optimSeuil=[] #vecteur de sortie des seuils, dans l'ordre des classes\n",
        "    optimAcc = [] #vecteur de sortie des précisions individualisées par classe\n",
        "    for i in range(4):\n",
        "        \n",
        "        classWeights = np.zeros(4)\n",
        "        classWeights[i]=1.\n",
        "        x, y = thresholdSweep(y_true, y_pred,\n",
        "                             classWeights = classWeights,verbose=0)\n",
        "        optimSeuil.append(x[y.index(np.max(y))])\n",
        "        optimAcc.append(np.max(y))\n",
        "\n",
        "    acc = np.mean(optimAcc)\n",
        "    seuils = np.round(optimSeuil,4)\n",
        "    accFit.append(acc)\n",
        "    accSeuils.append(seuils)\n",
        "    print('Lot ', iteration+1, ' : ', acc, ' - ', seuils)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k8rs5Ch-hKkI"
      },
      "source": [
        "Les évaluations et seuils optimaux sont moyennés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wFtFn5fNT9a",
        "outputId": "2318f00b-e493-444e-9a6e-a24e3c43d43d"
      },
      "outputs": [],
      "source": [
        "lst = [list(i) for i in zip(*accSeuils)]\n",
        "print(np.mean(lst, axis=1))\n",
        "print(f'\\nPrécison équivalente {np.mean(accFit):0.5f}')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_SvTMHoqhTpK"
      },
      "source": [
        "Nous retenons au final les seuils ci-dessous :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdVLr_6eZrSj"
      },
      "outputs": [],
      "source": [
        "maskSeuils = [.5,  .51, .48, .45]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3cjPzfN0peOP"
      },
      "source": [
        "#### **7.2.3 - Superficie et calcul des percentiles**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xlOfloMM2kdj"
      },
      "source": [
        "Il peut être intéressant de visualiser la distribution des surfaces du set d'apprentissage et celles du set de prédiction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "eoEmPcnLgMsj",
        "outputId": "561dde2e-ebce-4e9a-bb6d-c5fa8e181fe7"
      },
      "outputs": [],
      "source": [
        "def get_surfaces(classe, facteur):\n",
        "    surfaces = []\n",
        "\n",
        "    for rle in train_transformed[classe]:\n",
        "        if not isinstance(rle, float):\n",
        "            surfaces.append(packages.surfaceFromRle(rle) / facteur)\n",
        "\n",
        "    return surfaces\n",
        "\n",
        "facteur = (origin_size[0] * origin_size[1]) / (target_size[0] * target_size[1])\n",
        "surfaces = []\n",
        "surfaces.append(get_surfaces('Fish', facteur))\n",
        "surfaces.append(get_surfaces('Flower', facteur))\n",
        "surfaces.append(get_surfaces('Gravel', facteur))\n",
        "surfaces.append(get_surfaces('Sugar', facteur))\n",
        "histcolors=['b', 'r', 'g', 'y']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(30, 65))\n",
        "\n",
        "for i in range(len(formations_nuageuses)):\n",
        "    plt.subplot(8,4,i+1)\n",
        "    plt.hist(surfaces[i], bins=20, color=histcolors[i])\n",
        "    plt.title(\"Distribution des surfaces \" + formations_nuageuses[i] + \"\\n(set d'apprentissage)\\nmediane = \" + str(round(np.median(surfaces[i]),0)))\n",
        "    plt.xticks(rotation = 25)\n",
        "\n",
        "surfaces_predites = [None] * len(formations_nuageuses)\n",
        "for classe in range(len(formations_nuageuses)):\n",
        "    surfaces_predites[classe] = []\n",
        "    for lot in sub_pred:             #pour chaque lot ...\n",
        "\n",
        "        for i in range(len(lot)):    #... et chaque image\n",
        "\n",
        "            #On récupère les masques prédits pour l'ensemble des classes\n",
        "            pred_masks = lot[i, ]\n",
        "            seuil = maskSeuils[classe]\n",
        "            pred_mask = cv2.threshold(pred_masks[ :, :, classe], seuil, 1, cv2.THRESH_BINARY)[1]\n",
        "            surfaces_predites[classe].append(pred_mask.sum())\n",
        "\n",
        "for i in range(len(formations_nuageuses)):\n",
        "    plt.subplot(8,4,i+5)\n",
        "    plt.hist(surfaces_predites[i], bins=20, color=histcolors[i])\n",
        "    plt.title(\"Distribution des surfaces \" + formations_nuageuses[i] + \"\\n(set de predictions)\\nmediane = \" + str(round(np.median(surfaces_predites[i]),0)))\n",
        "    plt.xticks(rotation = 25)\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CRlq2WKm23DO"
      },
      "source": [
        "Nous pouvons constater que sur le set de prédiction, dans les valeurs faibles de surface il y a un nombre très important de petites surfaces. Pour les trois premières classes, ceci ramène la médiane à 0. Ces petites surfaces vont nuire à la performance du modèle, il nous faut les filtrer."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UQOKZCAogX-n"
      },
      "source": [
        "Ci-dessous un bon exemple de petites surfaces prédites. On peut en effet apercevoir des prédictions de formation nuageuse « Sucre » en jaune couvrant des surfaces relativement limitées."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "F6slAS3dNX-c",
        "outputId": "92924fe8-4364-4d33-8d1c-12755036bd4e"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "fig.suptitle(\"Exemple de surfaces réduites à filtrer\", fontsize=12)\n",
        "im1 = plt.imread(os.path.join(repTest, sub_imgs[3]))\n",
        "lot = sub_pred[0]\n",
        "\n",
        "surface_min = -1\n",
        "for k in range(4):\n",
        "    pred_masks1 = cv2.threshold(lot[30, :, :, k], maskSeuils[k], 1, cv2.THRESH_BINARY)[1]\n",
        "    packages.trace_boundingBox(im1, packages.np_transposition(pred_masks1, origin_size), color=couleurs[k])\n",
        "    if surface_min < 0 or pred_masks1.sum() < surface_min:\n",
        "        surface_min = pred_masks1.sum()\n",
        "\n",
        "ax.imshow(im1)  \n",
        "ax.set_title(\"Plus petite surface = \" + str(surface_min))\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cPEC0wMWgUU0"
      },
      "source": [
        "Pour filtrer ces prédictions \"parasites\" nous établissons tout d'abord, sur la base du set d'apprentissage, les percentiles des surfaces propres à chaque classe. Nous retenons au final arbitrairement le 15e percentile. Ainsi lors du post-traitement des prédictions, toutes les surfaces inférieures à ces valeurs seront supprimées."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK7clbsrHDaz",
        "outputId": "529ea26c-7c48-4e9d-a787-e958be6b23af"
      },
      "outputs": [],
      "source": [
        "def get_percentiles(classe, facteur):\n",
        "    surfaces = []\n",
        "\n",
        "    for rle in train_transformed[classe]:\n",
        "        if not isinstance(rle, float):\n",
        "            surfaces.append(packages.surfaceFromRle(rle))\n",
        "\n",
        "    return np.percentile(np.array(surfaces), [15, 50, 90]) / facteur\n",
        "\n",
        "facteur = (origin_size[0] * origin_size[1]) / (target_size[0] * target_size[1])\n",
        "\n",
        "percentiles = []\n",
        "percentiles.append(get_percentiles('Fish', facteur))\n",
        "percentiles.append(get_percentiles('Flower', facteur))\n",
        "percentiles.append(get_percentiles('Gravel', facteur))\n",
        "percentiles.append(get_percentiles('Sugar', facteur))\n",
        "\n",
        "for indice, classe in enumerate(formations_nuageuses):\n",
        "    print('15e percentile ', classe, ' : ', int(percentiles[indice][0]))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gYAtNmJXpli-"
      },
      "source": [
        "#### **7.2.4 - Post-traitements**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MMCWr5HL4CLM"
      },
      "source": [
        "Nous synthétisons dans cette partie les différents retraitements détaillés précédemment pour modifier les masques de prédictions en conséquence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3ShbpFpJxMQ"
      },
      "outputs": [],
      "source": [
        "def postTraitements(pred_mask, seuil, surface):\n",
        "\n",
        "    #Activation des pixels sur la base d'un seuil spécifique\n",
        "    pred_mask = cv2.threshold(pred_mask, seuil, 1, cv2.THRESH_BINARY)[1]\n",
        "\n",
        "    #on vérifie la superficie qui en résulte ...\n",
        "    # ... la taille minimale est atteinte, on retient ce masque\n",
        "    if pred_mask.sum() >= surface:\n",
        "        return pred_mask\n",
        "    \n",
        "    # ... la taille minimale n'est pas atteinte, on fait un reset du masque\n",
        "    return  np.zeros(pred_mask.shape, np.float32) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jKCAi4HcuMu"
      },
      "outputs": [],
      "source": [
        "#Pour chacun des lots on génère les encodage RLE associés aux prédictions\n",
        "#Il faut bien faire attention de spécifier la taille de masque attendue par Kaggle\n",
        "\n",
        "sub_rles = []\n",
        "\n",
        "for lot in sub_pred:             #pour chaque lot ...\n",
        "    for i in range(len(lot)):    #... et chaque image\n",
        "\n",
        "        #On récupère les masques prédits pour l'ensemble des classes\n",
        "        pred_masks = lot[i, ]\n",
        "\n",
        "        #Pour chaque classe ...\n",
        "        for classe in range(len(formations_nuageuses)):\n",
        "\n",
        "            #On récupère le seuil associé\n",
        "            seuil = maskSeuils[classe]\n",
        "\n",
        "            #ainsi que la surface minimum voulue\n",
        "            surface = percentiles[classe][0] \n",
        "\n",
        "            #Traitement du masque\n",
        "            pred_masks[ :, :, classe] = postTraitements(pred_masks[ :, :, classe], seuil, surface)\n",
        "\n",
        "        #Le traitement complémentaire étant terminé, on convertit les masques en code RLE\n",
        "        pred_rles = packages.list_maskToRle(pred_masks, reshape=submission_mask_size)\n",
        "        sub_rles.append(pred_rles)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2vwMRSGzpOyA"
      },
      "source": [
        "### **7.3 - Constitution du fichier de soumission Kaggle**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fEEPu_ko5Ir2"
      },
      "source": [
        "Pour finir, il nous suffit de compléter le dataframe de soumission, initialement créé, avec les prédictions. Le tout est exporté dans un fichier CSV au format attendu par Kaggle puis compressé."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_iYclUbdI2a"
      },
      "outputs": [],
      "source": [
        "#Mise à jour du dataframe de soumission avec les prédictions\n",
        "row = 0\n",
        "for prediction in sub_rles:\n",
        "    for i in range(len(formations_nuageuses)):\n",
        "        df_sub.EncodedPixels[row] = prediction[i]\n",
        "        row += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kFd6lOgc9yk"
      },
      "outputs": [],
      "source": [
        "#Mise en forme et sauvegarde du fichier de soumission Kaggle\n",
        "output_filename = 'nubela' \n",
        "final_sub = df_sub.drop(['image'], axis = 1)\n",
        "final_sub.to_csv(output_filename + '.csv', index=False)\n",
        "\n",
        "#Compression du fichier de sortie\n",
        "#Le site de la compétition Kaggle préconise un upload au format zip pour\n",
        "#gagner en temps de traitement\n",
        "zip_file = zipfile.ZipFile(output_filename + '.zip', 'w')\n",
        "zip_file.write(output_filename + '.csv', compress_type=zipfile.ZIP_DEFLATED)\n",
        "zip_file.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dCKHCdyw4BZz"
      },
      "source": [
        "### **7.4 - Scores Kaggle**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "y5X90bIT3-rB"
      },
      "source": [
        "L'ensemble tel qu'il a été présenté dans ce notebook obtient sur Kaggle les scores ci-dessous :\n",
        "-\tScore privé = 0.66016 (position 74)\n",
        "-\tScore public = 0.66173\n",
        "\n",
        "Pour rappel, le score public est établi sur 25% des données de test, le score privé, sur les 75% restant. Le score comptant au final dans le classement est le score privé.<br>\n",
        "On peut penser que l'ensemble de modèles est relativement performant dans la mesure ou les backbones choisis comptent un nombre relativement restreint de paramètres.<br>\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W517vVSjMB2H"
      },
      "source": [
        "## **8 - Prédictions ponctuelles**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "w18CLieWkrG0"
      },
      "source": [
        "### **8.1 - Prédictions sur la base d'un set de test**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OvBJv8AlYbEu"
      },
      "source": [
        "Nous allons effectuer des prédictions via le modèle 1 sur la base d'un lot test dans le seul but de visualiser en parallèles les masques associés aux prédictions brutes puis ceux associés aux prédictions post-traitées.\n",
        "\n",
        "Nous utilisons le set de test de 224 images mis de côté précédemment puis nous instancions un générateur sur celles-ci.<br>\n",
        "Enfin nous lançons la prédiction via le modèle 1 uniquement.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sbeqJHNgM-n",
        "outputId": "8e38a0a6-0dd4-4741-fe99-76bf4205139f"
      },
      "outputs": [],
      "source": [
        "batchSize = 32\n",
        "test_imgs = test_collector.tolist()\n",
        "\n",
        "#Instanciation d'un générateur\n",
        "test_generator = MultiGenerator(test_imgs,\n",
        "                              batch_size=batchSize, \n",
        "                              reshape=target_size,\n",
        "                              augment=False,\n",
        "                              shuffle=False,\n",
        "                              nb_canaux=nb_canaux,\n",
        "                              nb_classes=nb_classes)\n",
        "\n",
        "#Prédictions via le premier modèle\n",
        "prediction_masks1 = model1.predict(test_generator, workers=1, verbose=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Pev_4F9o7zVD"
      },
      "source": [
        "Les prédictions brutes ayant été générées, nous effectuons le post-traitement dans une structure dédiée pour conserver les prédictions brutes intactes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgL_axawBd5j"
      },
      "outputs": [],
      "source": [
        "#Post-traitement des prédictions\n",
        "\n",
        "#prediction_masks_processed = prediction_masks\n",
        "prediction_masks_processed = np.copy(prediction_masks1)\n",
        "       \n",
        "for i in range(len(prediction_masks_processed)):    # pour chaque image\n",
        "\n",
        "    #Pour chaque classe ...\n",
        "    for classe in range(len(formations_nuageuses)):\n",
        "\n",
        "        #On récupère le seuil associé\n",
        "        seuil = maskSeuils[classe]\n",
        "\n",
        "        #ainsi que la surface minimum voulue\n",
        "        surface = percentiles[classe][0] \n",
        "\n",
        "        #Traitement du masque\n",
        "        prediction_masks_processed[i, :, :, classe] = postTraitements(prediction_masks_processed[i, :, :, classe], seuil, surface)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D0094Bj88NNW"
      },
      "source": [
        "Enfin nous affichons quelques images au hasard afin de présenter pour chacune les zones d'origine, les zones prédites brutes, puis les zones prédites retraitées."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qyMgSkDapWNB",
        "outputId": "78cb7bc8-bb99-4c4e-b702-de97132ca46b"
      },
      "outputs": [],
      "source": [
        "#Confusion des prédictions et des données réelles\n",
        "\n",
        "fig, ax = plt.subplots(nrows=6, ncols=3, figsize=(20, 30), constrained_layout=True)\n",
        "\n",
        "nb_images = 6\n",
        "j= 0\n",
        "for i in random.sample(list(np.arange(0,test_size)), nb_images):\n",
        "\n",
        "    pred_masks = prediction_masks1[i, ].round().astype(int)\n",
        "    pred_rles = packages.list_maskToRle(pred_masks, reshape=origin_size)\n",
        "\n",
        "    pred_masks_processed = prediction_masks_processed[i, ].round().astype(int)\n",
        "    pred_rles_processed = packages.list_maskToRle(pred_masks_processed, reshape=origin_size)\n",
        "\n",
        "\n",
        "    im = plt.imread(os.path.join(repTrain, test_imgs[i]))\n",
        "    for indice, rle in enumerate(index_classes[test_imgs[i]]) :\n",
        "        if not isinstance(rle, float):\n",
        "            mask = packages.rleToMask(rle, origin_size)\n",
        "            packages.trace_boundingBox(im, mask, color=couleurs[indice]) \n",
        "    ax[j,0].imshow(im) \n",
        "    ax[j,0].set_title(\"Zones labellisées réelles\")   \n",
        "\n",
        "\n",
        "    im2 = plt.imread(os.path.join(repTrain, test_imgs[i]))\n",
        "    ax[j,1].set_title(\"Prévisions brutes\")        \n",
        "    for k in range(4):\n",
        "        mask = packages.rleToMask(pred_rles[k], origin_size)\n",
        "        im2 = packages.maskInColor(im2, mask, color=couleurs[k], alpha=0.3)\n",
        "    ax[j,1].imshow(im2)  \n",
        "\n",
        "    im3 = plt.imread(os.path.join(repTrain, test_imgs[i]))\n",
        "   \n",
        "    for k in range(4):\n",
        "        mask = packages.rleToMask(pred_rles_processed[k], origin_size)\n",
        "        packages.trace_boundingBox(im3, mask, color=couleurs[k])\n",
        "\n",
        "    ax[j,2].imshow(im3) \n",
        "    ax[j,2].set_title(\"Prévisions retraitées\") \n",
        "    \n",
        "    j+=1\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RY5BMp1gk5LL"
      },
      "source": [
        "### **8.2 - Prédictions d'image issues du module NASA earthdata**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bb9Vphx9cQ3"
      },
      "source": [
        "Le module EartView de la NASA offre la possibilité de charger des images satellite, pour un jour donné et au-dessus d'une zone donnée. Pour illustrer la capacité du modèle à identifier les formations nuageuses sur des images inconnues, nous soumettons ici une requête au module earthData afin de télécharger une image satellite prise au-dessus des caraïbes le 26/12/2019.\n",
        "\n",
        "Sur la base de la prédiction effectuée par notre modèle sur cette image nous colorons ensuite les formations nuageuses identifiées.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qOFnl9aiKNP"
      },
      "outputs": [],
      "source": [
        "#Récupération d'une photo satellite depuis l'appli worldview de la NASA\n",
        "def get_earthdataView(image_date, image_heure, target_size):\n",
        "    url = \"https://wvs.earthdata.nasa.gov/api/v1/snapshot?REQUEST=GetSnapshot&TIME=\"+image_date+\"T\"+image_heure+\"Z&BBOX=13.539855936494165,-46.89858946849988,25.854208633627493,-28.44241497728509&CRS=EPSG:4326&LAYERS=MODIS_Aqua_CorrectedReflectance_TrueColor,Coastlines_15m&WRAP=day,x&FORMAT=image/jpeg&WIDTH=2100&HEIGHT=1400&ts=1619077410459\"\n",
        "    im = Image.open(requests.get(url, stream=True).raw)\n",
        "    im = im.resize((target_size[1], target_size[0]), Image.ANTIALIAS)  \n",
        "    return im\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "dOPKVqZyla_Q",
        "outputId": "a794b934-8f91-495c-e9b5-6ee08ba0e87e"
      },
      "outputs": [],
      "source": [
        "#Définition de la date et de l'heure voulues\n",
        "image_date = '2019-02-26'\n",
        "image_heure = '08:00:00'\n",
        "\n",
        "#Récupération de l'image\n",
        "im = get_earthdataView(image_date, image_heure, target_size)\n",
        "\n",
        "#Conversion en tensor\n",
        "im_tensor = packages.imageToTensor(im)\n",
        "\n",
        "#Prédictions\n",
        "preds_nasa= model1.predict(im_tensor, verbose=1)\n",
        "\n",
        "do_postTraitement = True\n",
        "\n",
        "if do_postTraitement:\n",
        "    #Post-traitement des prédictions\n",
        "    for i in range(len(preds_nasa)):    \n",
        "\n",
        "        #Pour chaque classe ...\n",
        "        for classe in range(len(formations_nuageuses)):\n",
        "\n",
        "            #On récupère le seuil associé\n",
        "            seuil = maskSeuils[classe]\n",
        "\n",
        "            #ainsi que la surface minimum voulue\n",
        "            surface = percentiles[classe][0] \n",
        "\n",
        "            #Traitement du masque\n",
        "            preds_nasa[i, :, :, classe] = postTraitements(preds_nasa[i, :, :, classe], seuil, surface)\n",
        "\n",
        "preds_nasa_masks = preds_nasa[0, ].round().astype(int)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "im3 = np.array(im)\n",
        "\n",
        "for k in range(4):\n",
        "    mask = (preds_nasa_masks[:,:,k]).astype(np.uint8)\n",
        "    im3 = packages.cloudInColor(im3, mask, color=couleurs[k], alpha=0.7, threshold=90)\n",
        "\n",
        "ax.imshow(im3) \n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "nebula_phase3_segmentation_vf.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
